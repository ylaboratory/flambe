{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare different BERT models for the tissue and cell type NER task\n",
    "Fine tune existing bioNER models for biomedical tissue and cell type prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Features, Sequence, Value, ClassLabel\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, DataCollatorForTokenClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from iob_functions import *\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(6002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"../data/\"\n",
    "\n",
    "training_f = process_tab_delim_iob(BASE_DIR + 'tags/fulltext_iob/fulltext_tissues_train.iob')\n",
    "training_a = process_tab_delim_iob(BASE_DIR + 'tags/abstract_iob/abstract_tissues_train.iob')\n",
    "training = {'sentences': training_f['sentences'] + training_a['sentences'], 'tags': training_f['tags'] + training_a['tags']}\n",
    "\n",
    "valid_f = process_tab_delim_iob(BASE_DIR + 'tags/fulltext_iob/fulltext_tissues_validation.iob')\n",
    "valid_a = process_tab_delim_iob(BASE_DIR + 'tags/abstract_iob/abstract_tissues_validation.iob')\n",
    "validation = {'sentences': valid_f['sentences'] + valid_a['sentences'], 'tags': valid_f['tags'] + valid_a['tags']}\n",
    "\n",
    "test_f = process_tab_delim_iob(BASE_DIR + 'tags/fulltext_iob/fulltext_tissues_test.iob')\n",
    "test_a = process_tab_delim_iob(BASE_DIR + 'tags/abstract_iob/abstract_tissues_test.iob')\n",
    "test = {'sentences': test_f['sentences'] + test_a['sentences'], 'tags': test_f['tags'] + test_a['tags']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Features({\"tokens\": Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
    "                     \"tags\": Sequence(feature=ClassLabel(names=[\"O\", \"B-CELL_TYPE\", \"I-CELL_TYPE\", \"B-TISSUE\", \"I-TISSUE\"]))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = Dataset.from_dict({\"tokens\": training['sentences'], \"tags\": training['tags']}, features=features)\n",
    "validation_ds = Dataset.from_dict({\"tokens\": validation['sentences'], \"tags\": validation['tags']}, features=features)\n",
    "test_ds = Dataset.from_dict({\"tokens\": test['sentences'], \"tags\": test['tags']}, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = training_ds.features[\"tags\"].feature\n",
    "tag_list = training_ds.features[\"tags\"].feature.names\n",
    "id2tag = {idx: tag for idx, tag in enumerate(all_tags.names)}\n",
    "tag2id = {tag: idx for idx, tag in enumerate(all_tags.names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of models to run\n",
    "m_names = ['bert-base-uncased', 'google/electra-base-discriminator',\n",
    "           'dmis-lab/biobert-base-cased-v1.2', 'bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12',\n",
    "           'kamalkraj/bioelectra-base-discriminator-pubmed',\n",
    "           'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract']\n",
    "MAX_LENGTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://huggingface.co/docs/transformers/tasks/token_classification\n",
    "def tokenize_and_align_labels(data, tknzr, max_length=50):\n",
    "    tokenized_inputs = tknzr(data['tokens'], truncation=True, is_split_into_words=True, max_length=max_length)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(data['tags']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "    \n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [tag_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [tag_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    f1res = precision_recall_fscore_support(flatten(true_labels), flatten(true_predictions), labels=all_tags.names)\n",
    "\n",
    "    df = list(zip(all_tags.names, f1res[2], f1res[0], f1res[1]))\n",
    "    df = pd.DataFrame(df, columns = ['Level', 'F1-Score', 'Precision', 'Recall'])   \n",
    "    print(df)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009e418e8b6f447d9bbe3b82bd69a4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20596 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe35a50c59045679a8d37d3d025c8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3499 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4264537d5c5846179987ea7686426adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5753 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7725' max='7725' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7725/7725 10:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Cell Type</th>\n",
       "      <th>Tissue</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.011733</td>\n",
       "      <td>{'precision': 0.6870026525198939, 'recall': 0.7617647058823529, 'f1': 0.7224546722454672, 'number': 340}</td>\n",
       "      <td>{'precision': 0.7286324786324786, 'recall': 0.8197115384615384, 'f1': 0.7714932126696833, 'number': 416}</td>\n",
       "      <td>0.710059</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.749532</td>\n",
       "      <td>0.995312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.011885</td>\n",
       "      <td>{'precision': 0.723463687150838, 'recall': 0.7617647058823529, 'f1': 0.7421203438395416, 'number': 340}</td>\n",
       "      <td>{'precision': 0.8055555555555556, 'recall': 0.8365384615384616, 'f1': 0.8207547169811321, 'number': 416}</td>\n",
       "      <td>0.768354</td>\n",
       "      <td>0.802910</td>\n",
       "      <td>0.785252</td>\n",
       "      <td>0.996181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.012458</td>\n",
       "      <td>{'precision': 0.7378917378917379, 'recall': 0.7617647058823529, 'f1': 0.7496382054992764, 'number': 340}</td>\n",
       "      <td>{'precision': 0.8211764705882353, 'recall': 0.8389423076923077, 'f1': 0.8299643281807373, 'number': 416}</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.804233</td>\n",
       "      <td>0.793734</td>\n",
       "      <td>0.996340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.998034   0.998535  0.997532\n",
      "1  B-CELL_TYPE  0.767164   0.769461  0.764881\n",
      "2  I-CELL_TYPE  0.807095   0.764706  0.854460\n",
      "3     B-TISSUE  0.814469   0.789593  0.840964\n",
      "4     I-TISSUE  0.772947   0.672269  0.909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.998431   0.998475  0.998388\n",
      "1  B-CELL_TYPE  0.790087   0.774286  0.806548\n",
      "2  I-CELL_TYPE  0.844125   0.862745  0.826291\n",
      "3     B-TISSUE  0.846246   0.837264  0.855422\n",
      "4     I-TISSUE  0.804734   0.839506  0.772727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.998487   0.998364  0.998611\n",
      "1  B-CELL_TYPE  0.795888   0.785507  0.806548\n",
      "2  I-CELL_TYPE  0.837905   0.893617  0.788732\n",
      "3     B-TISSUE  0.859206   0.858173  0.860241\n",
      "4     I-TISSUE  0.807018   0.831325  0.784091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.996751   0.998090  0.995414\n",
      "1  B-CELL_TYPE  0.824847   0.776854  0.879161\n",
      "2  I-CELL_TYPE  0.860260   0.820614  0.903930\n",
      "3     B-TISSUE  0.860465   0.850150  0.871034\n",
      "4     I-TISSUE  0.636842   0.550000  0.756250\n",
      "google/electra-base-discriminator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd21ddf21a074a90873930a987f5ba51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20596 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2cee00ca504ed98e2a94c99834d0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3499 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0153771357004d7e893a255979e974ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5753 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForTokenClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7725' max='7725' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7725/7725 10:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Cell Type</th>\n",
       "      <th>Tissue</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>{'precision': 0.7254335260115607, 'recall': 0.7382352941176471, 'f1': 0.7317784256559767, 'number': 340}</td>\n",
       "      <td>{'precision': 0.7349896480331263, 'recall': 0.8533653846153846, 'f1': 0.789766407119021, 'number': 416}</td>\n",
       "      <td>0.731001</td>\n",
       "      <td>0.801587</td>\n",
       "      <td>0.764669</td>\n",
       "      <td>0.995397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.012211</td>\n",
       "      <td>{'precision': 0.6971279373368147, 'recall': 0.7852941176470588, 'f1': 0.7385892116182573, 'number': 340}</td>\n",
       "      <td>{'precision': 0.822429906542056, 'recall': 0.8461538461538461, 'f1': 0.8341232227488151, 'number': 416}</td>\n",
       "      <td>0.763255</td>\n",
       "      <td>0.818783</td>\n",
       "      <td>0.790045</td>\n",
       "      <td>0.996058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>{'precision': 0.6939313984168866, 'recall': 0.7735294117647059, 'f1': 0.7315716272600835, 'number': 340}</td>\n",
       "      <td>{'precision': 0.8136363636363636, 'recall': 0.8605769230769231, 'f1': 0.836448598130841, 'number': 416}</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.788571</td>\n",
       "      <td>0.996009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.998059   0.998412  0.997706\n",
      "1  B-CELL_TYPE  0.744395   0.747748  0.741071\n",
      "2  I-CELL_TYPE  0.813559   0.840000  0.788732\n",
      "3     B-TISSUE  0.826577   0.775899  0.884337\n",
      "4     I-TISSUE  0.806283   0.747573  0.875000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.998350   0.998610  0.998090\n",
      "1  B-CELL_TYPE  0.771186   0.733871  0.812500\n",
      "2  I-CELL_TYPE  0.838710   0.823529  0.854460\n",
      "3     B-TISSUE  0.850356   0.838407  0.862651\n",
      "4     I-TISSUE  0.876543   0.959459  0.806818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.998338   0.998573  0.998103\n",
      "1  B-CELL_TYPE  0.759207   0.724324  0.797619\n",
      "2  I-CELL_TYPE  0.834146   0.868020  0.802817\n",
      "3     B-TISSUE  0.857814   0.837156  0.879518\n",
      "4     I-TISSUE  0.857143   0.862069  0.852273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.997033   0.997600  0.996468\n",
      "1  B-CELL_TYPE  0.825694   0.793725  0.860347\n",
      "2  I-CELL_TYPE  0.875682   0.874728  0.876638\n",
      "3     B-TISSUE  0.868902   0.862765  0.875128\n",
      "4     I-TISSUE  0.700000   0.661111  0.743750\n",
      "dmis-lab/biobert-base-cased-v1.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0816f160a0456f945c888fd67e4c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20596 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254d50a7f52349cda25943dede2198b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3499 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b2e629c1b640f5a324af0239889bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5753 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7725' max='7725' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7725/7725 10:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Cell Type</th>\n",
       "      <th>Tissue</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.010158</td>\n",
       "      <td>{'precision': 0.7450424929178471, 'recall': 0.775811209439528, 'f1': 0.7601156069364162, 'number': 339}</td>\n",
       "      <td>{'precision': 0.7591397849462366, 'recall': 0.8485576923076923, 'f1': 0.8013620885357549, 'number': 416}</td>\n",
       "      <td>0.753056</td>\n",
       "      <td>0.815894</td>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.996081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.011037</td>\n",
       "      <td>{'precision': 0.6649616368286445, 'recall': 0.7669616519174042, 'f1': 0.7123287671232877, 'number': 339}</td>\n",
       "      <td>{'precision': 0.8087557603686636, 'recall': 0.84375, 'f1': 0.8258823529411765, 'number': 416}</td>\n",
       "      <td>0.740606</td>\n",
       "      <td>0.809272</td>\n",
       "      <td>0.773418</td>\n",
       "      <td>0.995922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.011515</td>\n",
       "      <td>{'precision': 0.6857142857142857, 'recall': 0.7787610619469026, 'f1': 0.729281767955801, 'number': 339}</td>\n",
       "      <td>{'precision': 0.8175519630484989, 'recall': 0.8509615384615384, 'f1': 0.8339222614840989, 'number': 416}</td>\n",
       "      <td>0.755501</td>\n",
       "      <td>0.818543</td>\n",
       "      <td>0.785760</td>\n",
       "      <td>0.996253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.998411   0.998746  0.998077\n",
      "1  B-CELL_TYPE  0.792846   0.791667  0.794030\n",
      "2  I-CELL_TYPE  0.845411   0.870647  0.821596\n",
      "3     B-TISSUE  0.840779   0.801310  0.884337\n",
      "4     I-TISSUE  0.787879   0.709091  0.886364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.998331   0.998585  0.998077\n",
      "1  B-CELL_TYPE  0.743590   0.711172  0.779104\n",
      "2  I-CELL_TYPE  0.836879   0.842857  0.830986\n",
      "3     B-TISSUE  0.852768   0.834101  0.872289\n",
      "4     I-TISSUE  0.863905   0.901235  0.829545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.998499   0.998722  0.998276\n",
      "1  B-CELL_TYPE  0.765957   0.729730  0.805970\n",
      "2  I-CELL_TYPE  0.845411   0.870647  0.821596\n",
      "3     B-TISSUE  0.865248   0.849188  0.881928\n",
      "4     I-TISSUE  0.843931   0.858824  0.829545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.997079   0.998435  0.995727\n",
      "1  B-CELL_TYPE  0.836401   0.790593  0.887844\n",
      "2  I-CELL_TYPE  0.864453   0.862106  0.866812\n",
      "3     B-TISSUE  0.868255   0.826852  0.914023\n",
      "4     I-TISSUE  0.730864   0.604082  0.925000\n",
      "bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c069dcc84cd34894acd6fbf21a960bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20596 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1cad9fe4544c32b9453fef13d703ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3499 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac92d8ff98d48f69b612c8ba2a6f67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5753 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7725' max='7725' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7725/7725 10:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Cell Type</th>\n",
       "      <th>Tissue</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.010856</td>\n",
       "      <td>{'precision': 0.6486486486486487, 'recall': 0.7764705882352941, 'f1': 0.7068273092369479, 'number': 340}</td>\n",
       "      <td>{'precision': 0.7680525164113785, 'recall': 0.84375, 'f1': 0.8041237113402061, 'number': 416}</td>\n",
       "      <td>0.711806</td>\n",
       "      <td>0.813492</td>\n",
       "      <td>0.759259</td>\n",
       "      <td>0.995410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.011042</td>\n",
       "      <td>{'precision': 0.6537530266343826, 'recall': 0.7941176470588235, 'f1': 0.7171314741035856, 'number': 340}</td>\n",
       "      <td>{'precision': 0.8167053364269141, 'recall': 0.8461538461538461, 'f1': 0.8311688311688311, 'number': 416}</td>\n",
       "      <td>0.736967</td>\n",
       "      <td>0.822751</td>\n",
       "      <td>0.777500</td>\n",
       "      <td>0.995961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.011515</td>\n",
       "      <td>{'precision': 0.7150684931506849, 'recall': 0.7676470588235295, 'f1': 0.7404255319148936, 'number': 340}</td>\n",
       "      <td>{'precision': 0.8177676537585421, 'recall': 0.8629807692307693, 'f1': 0.8397660818713449, 'number': 416}</td>\n",
       "      <td>0.771144</td>\n",
       "      <td>0.820106</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.996413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.998126   0.999068  0.997185\n",
      "1  B-CELL_TYPE  0.755304   0.719677  0.794643\n",
      "2  I-CELL_TYPE  0.788501   0.700730  0.901408\n",
      "3     B-TISSUE  0.846154   0.819413  0.874699\n",
      "4     I-TISSUE  0.803922   0.706897  0.931818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.998350   0.998908  0.997793\n",
      "1  B-CELL_TYPE  0.762689   0.707379  0.827381\n",
      "2  I-CELL_TYPE  0.815145   0.775424  0.859155\n",
      "3     B-TISSUE  0.859524   0.849412  0.869880\n",
      "4     I-TISSUE  0.886364   0.886364  0.886364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.998567   0.998759  0.998376\n",
      "1  B-CELL_TYPE  0.779562   0.765043  0.794643\n",
      "2  I-CELL_TYPE  0.838095   0.850242  0.826291\n",
      "3     B-TISSUE  0.867612   0.851508  0.884337\n",
      "4     I-TISSUE  0.869565   0.833333  0.909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.996756   0.998912  0.994608\n",
      "1  B-CELL_TYPE  0.813526   0.744591  0.896527\n",
      "2  I-CELL_TYPE  0.866094   0.806209  0.935590\n",
      "3     B-TISSUE  0.869608   0.843269  0.897646\n",
      "4     I-TISSUE  0.725926   0.600000  0.918750\n",
      "kamalkraj/bioelectra-base-discriminator-pubmed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290944841da84ee9a4f4b3db324eef07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20596 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330862cb398e4d06b8f63640ba28efa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3499 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12f80ab6c444d0d88e39f2da8ef55ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5753 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForTokenClassification were not initialized from the model checkpoint at kamalkraj/bioelectra-base-discriminator-pubmed and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7725' max='7725' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7725/7725 10:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Cell Type</th>\n",
       "      <th>Tissue</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.010314</td>\n",
       "      <td>{'precision': 0.6827956989247311, 'recall': 0.7448680351906158, 'f1': 0.7124824684431976, 'number': 341}</td>\n",
       "      <td>{'precision': 0.7565922920892495, 'recall': 0.8966346153846154, 'f1': 0.8206820682068207, 'number': 416}</td>\n",
       "      <td>0.724855</td>\n",
       "      <td>0.828269</td>\n",
       "      <td>0.773120</td>\n",
       "      <td>0.996001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.010090</td>\n",
       "      <td>{'precision': 0.6585956416464891, 'recall': 0.7976539589442815, 'f1': 0.7214854111405835, 'number': 341}</td>\n",
       "      <td>{'precision': 0.8013245033112583, 'recall': 0.8725961538461539, 'f1': 0.8354430379746836, 'number': 416}</td>\n",
       "      <td>0.733256</td>\n",
       "      <td>0.838838</td>\n",
       "      <td>0.782502</td>\n",
       "      <td>0.996160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.010488</td>\n",
       "      <td>{'precision': 0.7017994858611826, 'recall': 0.8005865102639296, 'f1': 0.7479452054794522, 'number': 341}</td>\n",
       "      <td>{'precision': 0.8314350797266514, 'recall': 0.8774038461538461, 'f1': 0.8538011695906431, 'number': 416}</td>\n",
       "      <td>0.770531</td>\n",
       "      <td>0.842801</td>\n",
       "      <td>0.805047</td>\n",
       "      <td>0.996539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.998376   0.999057  0.997696\n",
      "1  B-CELL_TYPE  0.775036   0.758523  0.792285\n",
      "2  I-CELL_TYPE  0.825986   0.816514  0.835681\n",
      "3     B-TISSUE  0.855556   0.793814  0.927711\n",
      "4     I-TISSUE  0.836735   0.759259  0.931818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.998438   0.999020  0.997857\n",
      "1  B-CELL_TYPE  0.774629   0.710396  0.851632\n",
      "2  I-CELL_TYPE  0.833724   0.831776  0.835681\n",
      "3     B-TISSUE  0.870070   0.838926  0.903614\n",
      "4     I-TISSUE  0.847059   0.878049  0.818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.998544   0.998958  0.998129\n",
      "1  B-CELL_TYPE  0.794944   0.754667  0.839763\n",
      "2  I-CELL_TYPE  0.846512   0.838710  0.854460\n",
      "3     B-TISSUE  0.888104   0.868664  0.908434\n",
      "4     I-TISSUE  0.868132   0.840426  0.897727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.996909   0.998637  0.995187\n",
      "1  B-CELL_TYPE  0.818656   0.745249  0.908104\n",
      "2  I-CELL_TYPE  0.871550   0.848140  0.896288\n",
      "3     B-TISSUE  0.869354   0.833333  0.908629\n",
      "4     I-TISSUE  0.776471   0.733333  0.825000\n",
      "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075771c362954f5d8a9b8bab1eae5fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20596 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb96c590a0a4145933855fb7bcb01dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3499 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e627d4594eca4fa3aeb0f5289911ccd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5753 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7725' max='7725' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7725/7725 10:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Cell Type</th>\n",
       "      <th>Tissue</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.009903</td>\n",
       "      <td>{'precision': 0.6878306878306878, 'recall': 0.7624633431085044, 'f1': 0.7232267037552156, 'number': 341}</td>\n",
       "      <td>{'precision': 0.8080357142857143, 'recall': 0.8701923076923077, 'f1': 0.837962962962963, 'number': 416}</td>\n",
       "      <td>0.753027</td>\n",
       "      <td>0.821664</td>\n",
       "      <td>0.785850</td>\n",
       "      <td>0.996148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.009919</td>\n",
       "      <td>{'precision': 0.7191601049868767, 'recall': 0.8035190615835777, 'f1': 0.7590027700831025, 'number': 341}</td>\n",
       "      <td>{'precision': 0.7986725663716814, 'recall': 0.8677884615384616, 'f1': 0.8317972350230414, 'number': 416}</td>\n",
       "      <td>0.762305</td>\n",
       "      <td>0.838838</td>\n",
       "      <td>0.798742</td>\n",
       "      <td>0.996490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.011077</td>\n",
       "      <td>{'precision': 0.7342465753424657, 'recall': 0.7859237536656891, 'f1': 0.7592067988668555, 'number': 341}</td>\n",
       "      <td>{'precision': 0.8216704288939052, 'recall': 0.875, 'f1': 0.8474970896391152, 'number': 416}</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.834875</td>\n",
       "      <td>0.807668</td>\n",
       "      <td>0.996612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.998420   0.998822  0.998018\n",
      "1  B-CELL_TYPE  0.766764   0.753582  0.780415\n",
      "2  I-CELL_TYPE  0.825688   0.807175  0.845070\n",
      "3     B-TISSUE  0.873832   0.848073  0.901205\n",
      "4     I-TISSUE  0.839378   0.771429  0.920455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.998637   0.999045  0.998228\n",
      "1  B-CELL_TYPE  0.793201   0.758808  0.830861\n",
      "2  I-CELL_TYPE  0.829493   0.814480  0.845070\n",
      "3     B-TISSUE  0.875000   0.841871  0.910843\n",
      "4     I-TISSUE  0.845238   0.887500  0.806818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.998662   0.998884  0.998439\n",
      "1  B-CELL_TYPE  0.790765   0.769663  0.813056\n",
      "2  I-CELL_TYPE  0.847458   0.875000  0.821596\n",
      "3     B-TISSUE  0.879250   0.856164  0.903614\n",
      "4     I-TISSUE  0.852459   0.821053  0.886364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/vy3/conda/envs/flambe/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Level  F1-Score  Precision    Recall\n",
      "0            O  0.997243   0.998414  0.996075\n",
      "1  B-CELL_TYPE  0.829135   0.782776  0.881331\n",
      "2  I-CELL_TYPE  0.873091   0.843337  0.905022\n",
      "3     B-TISSUE  0.892929   0.888442  0.897462\n",
      "4     I-TISSUE  0.767624   0.659193  0.918750\n"
     ]
    }
   ],
   "source": [
    "test_metrics = dict()\n",
    "\n",
    "for m in m_names:\n",
    "    print(m)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(m)\n",
    "    # dynamically pad sentences to longest length in batch for efficiency\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "    train_tokenized = training_ds.map(tokenize_and_align_labels, batched=True, fn_kwargs={'tknzr': tokenizer, 'max_length': MAX_LENGTH})\n",
    "    val_tokenized = validation_ds.map(tokenize_and_align_labels, batched=True, fn_kwargs={'tknzr': tokenizer, 'max_length': MAX_LENGTH})\n",
    "    test_tokenized = test_ds.map(tokenize_and_align_labels, batched=True, fn_kwargs={'tknzr': tokenizer, 'max_length': MAX_LENGTH})\n",
    "\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        m, num_labels=5, id2label=id2tag, label2id=tag2id\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"model/\" + m,\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        push_to_hub=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_tokenized,\n",
    "        eval_dataset=val_tokenized,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    test_preds = trainer.predict(test_tokenized)\n",
    "    test_metrics[m] = test_preds.metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert-base-uncased': {'test_loss': 0.02012392319738865,\n",
       "  'test_CELL_TYPE': {'precision': 0.7203182374541004,\n",
       "   'recall': 0.8479827089337176,\n",
       "   'f1': 0.7789543348775645,\n",
       "   'number': 1388},\n",
       "  'test_TISSUE': {'precision': 0.775096525096525,\n",
       "   'recall': 0.8219037871033776,\n",
       "   'f1': 0.7978142076502731,\n",
       "   'number': 977},\n",
       "  'test_overall_precision': 0.7415730337078652,\n",
       "  'test_overall_recall': 0.8372093023255814,\n",
       "  'test_overall_f1': 0.7864945382323734,\n",
       "  'test_overall_accuracy': 0.9924709651581898,\n",
       "  'test_runtime': 23.2553,\n",
       "  'test_samples_per_second': 247.384,\n",
       "  'test_steps_per_second': 30.961},\n",
       " 'google/electra-base-discriminator': {'test_loss': 0.02117023430764675,\n",
       "  'test_CELL_TYPE': {'precision': 0.7675033025099075,\n",
       "   'recall': 0.8371757925072046,\n",
       "   'f1': 0.8008270158511371,\n",
       "   'number': 1388},\n",
       "  'test_TISSUE': {'precision': 0.8149253731343283,\n",
       "   'recall': 0.8382804503582395,\n",
       "   'f1': 0.8264379414732594,\n",
       "   'number': 977},\n",
       "  'test_overall_precision': 0.7864231838030965,\n",
       "  'test_overall_recall': 0.8376321353065539,\n",
       "  'test_overall_f1': 0.8112203112203111,\n",
       "  'test_overall_accuracy': 0.9931408599410201,\n",
       "  'test_runtime': 23.2573,\n",
       "  'test_samples_per_second': 247.363,\n",
       "  'test_steps_per_second': 30.958},\n",
       " 'dmis-lab/biobert-base-cased-v1.2': {'test_loss': 0.01749158464372158,\n",
       "  'test_CELL_TYPE': {'precision': 0.7400881057268722,\n",
       "   'recall': 0.8472622478386167,\n",
       "   'f1': 0.7900571044675848,\n",
       "   'number': 1388},\n",
       "  'test_TISSUE': {'precision': 0.7760511882998172,\n",
       "   'recall': 0.8689866939611054,\n",
       "   'f1': 0.8198937711250603,\n",
       "   'number': 977},\n",
       "  'test_overall_precision': 0.7547521431233694,\n",
       "  'test_overall_recall': 0.8562367864693446,\n",
       "  'test_overall_f1': 0.80229793977813,\n",
       "  'test_overall_accuracy': 0.9931176624814286,\n",
       "  'test_runtime': 23.0582,\n",
       "  'test_samples_per_second': 249.499,\n",
       "  'test_steps_per_second': 31.225},\n",
       " 'bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12': {'test_loss': 0.01927519030869007,\n",
       "  'test_CELL_TYPE': {'precision': 0.7061224489795919,\n",
       "   'recall': 0.872478386167147,\n",
       "   'f1': 0.7805349661617789,\n",
       "   'number': 1388},\n",
       "  'test_TISSUE': {'precision': 0.7904583723105706,\n",
       "   'recall': 0.8648925281473899,\n",
       "   'f1': 0.826001955034213,\n",
       "   'number': 977},\n",
       "  'test_overall_precision': 0.7385057471264368,\n",
       "  'test_overall_recall': 0.8693446088794926,\n",
       "  'test_overall_f1': 0.7986016702272286,\n",
       "  'test_overall_accuracy': 0.9924491207630975,\n",
       "  'test_runtime': 23.237,\n",
       "  'test_samples_per_second': 247.579,\n",
       "  'test_steps_per_second': 30.985},\n",
       " 'kamalkraj/bioelectra-base-discriminator-pubmed': {'test_loss': 0.018675636500120163,\n",
       "  'test_CELL_TYPE': {'precision': 0.7101110461718293,\n",
       "   'recall': 0.8753602305475504,\n",
       "   'f1': 0.7841239109390126,\n",
       "   'number': 1388},\n",
       "  'test_TISSUE': {'precision': 0.8033395176252319,\n",
       "   'recall': 0.8791878172588833,\n",
       "   'f1': 0.8395540475036356,\n",
       "   'number': 985},\n",
       "  'test_overall_precision': 0.7461455718895662,\n",
       "  'test_overall_recall': 0.8769490096923725,\n",
       "  'test_overall_f1': 0.8062766369624178,\n",
       "  'test_overall_accuracy': 0.9928336534543973,\n",
       "  'test_runtime': 22.7974,\n",
       "  'test_samples_per_second': 252.354,\n",
       "  'test_steps_per_second': 31.583},\n",
       " 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract': {'test_loss': 0.017329642549157143,\n",
       "  'test_CELL_TYPE': {'precision': 0.7370049504950495,\n",
       "   'recall': 0.8580691642651297,\n",
       "   'f1': 0.792942743009321,\n",
       "   'number': 1388},\n",
       "  'test_TISSUE': {'precision': 0.8298918387413963,\n",
       "   'recall': 0.8568527918781725,\n",
       "   'f1': 0.8431568431568431,\n",
       "   'number': 985},\n",
       "  'test_overall_precision': 0.7728826433725788,\n",
       "  'test_overall_recall': 0.8575642646439107,\n",
       "  'test_overall_f1': 0.8130243707550938,\n",
       "  'test_overall_accuracy': 0.9935175484546883,\n",
       "  'test_runtime': 22.7876,\n",
       "  'test_samples_per_second': 252.462,\n",
       "  'test_steps_per_second': 31.596}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
